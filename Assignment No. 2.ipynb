{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac099da9",
   "metadata": {},
   "source": [
    "1) What are Corpora ?\n",
    "\n",
    ":- A collection of authentic text & audio organized into dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a2dd4",
   "metadata": {},
   "source": [
    "2) What are tokens ?\n",
    "\n",
    ":- A token is an instance of a sequence of characters in some particular document that are grouped together as a useful        semantic unit for processing. A type is the class of all tokens containing the same character sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b331cce9",
   "metadata": {},
   "source": [
    "3) What are Unigrams, Bigrams, Trigrams?\n",
    "\n",
    ":- Unigrams means one word, bigrams means two word, trigrams means three word. It can explained from following          example:-\n",
    "\n",
    "   Unigrams - [Let] [me] [explain] [with] [an] [example]\n",
    "   Bigrams - [Let me] [me explain] [explain with] [with an] [an example]\n",
    "   Trigrams - [let me explain] [me explain with] [explain with an] [with an example]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5263ffe6",
   "metadata": {},
   "source": [
    "4) How to generate n-grams from text?\n",
    "\n",
    ":- N-Grams are phrases cut out of a sentence with N cinsecutive words.\n",
    "   i) Copy a text (from a website, a book, a larger corpus, et cetera).\n",
    "   ii) Paste the text into the input area below. You don't have to remove weird characters, tags, white spaces and new             lines â€” the script does it for you.\n",
    "   iii) Set 'ngram' to the desired number of words or leave at 2 (bigrams) and set the number of results wanted (or leave           at 50). If you're going to sort on probablity (see 'explanation'), it can be useful to set a minimal frequency for         the n-grams included in the list.\n",
    "   iv) Click 'Generate ngrams' and wait a bit.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6caff6",
   "metadata": {},
   "source": [
    "5) Explain Lemmatization\n",
    "\n",
    ":- Lemmatization is the grouping together of different forms of the same word. For example runs, running, ran are all forms    of the word run, therefore run is the lemma of all these words. It does not come to root word. It is the root form of      the word. Lemmatization makes meaningful word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a1890",
   "metadata": {},
   "source": [
    "6) Explain Stemming\n",
    "\n",
    ":- Stemming is a process that stems or removes last few characters from a word, often leading to incorrect meanings and        spelling. It is the process of reducing the word to its root form\n",
    "   e.g:- History = Histori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622eb71b",
   "metadata": {},
   "source": [
    "7) Explain Part-of-speech (POS) tagging\n",
    "\n",
    ":- Part-of-speech (POS) tagging is a popular Natural Language Processing process which refers to categorizing words in a      text (corpus) in correspondence with a particular part of speech, depending on the definition of the word and its          context. In more simple way it is a task of labelling each word in a sentence with its appropriate part of speech. We      already know that parts of speech include nouns, verb, adverbs, adjectives, pronouns, conjunction and their sub-            categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b96b9a",
   "metadata": {},
   "source": [
    "8) Explain Chunking or shallow parsing\n",
    "\n",
    ":- It is an analysis of a sentence which first identifies constituent parts of sentences (nouns, verbs, adjectives, etc.)      and then links them to higher order units that have discrete grammatical meanings (noun groups or phrases, verb groups,        etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d12fe5",
   "metadata": {},
   "source": [
    "9) Explain Noun Phrase (NP) chunking\n",
    "\n",
    ":-  NP-chunks are often smaller pieces than complete noun phrases. For example, the market for system-management software      for Digital's hardware is a single noun phrase (containing two nested noun phrases), but it is captured in NP-chunks by    the simpler chunk the market. One of the motivations for this difference is that NP-chunks are defined so as not to        contain other NP-chunks. Consequently, any prepositional phrases or subordinate clauses that modify a nominal will not      be included in the corresponding NP-chunk, since they almost certainly contain further noun phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91999eb",
   "metadata": {},
   "source": [
    "10) Explain Named Entity Recognition\n",
    "\n",
    ":-\n",
    "    \n",
    "The named entity recognition (NER) is one of the most data preprocessing task. It involves the identification of key information in the text and classification into a set of predefined categories. An entity is basically the thing that is consistently talked about or refer to in the text.\n",
    "\n",
    "NER is the form of NLP.\n",
    "\n",
    "At its core, NLP is just a two-step process, below are the two steps that are involved:\n",
    "\n",
    "Detecting the entities from the text\n",
    "Classifying them into different categories\n",
    "Some of the categories that are the most important architecture in NER such that:\n",
    "\n",
    "Person\n",
    "Organization\n",
    "Place/ location\n",
    "date/time.\n",
    "expression\n",
    "Numeral measurement (money, percent, weight, etc)\n",
    "E-mail address\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
